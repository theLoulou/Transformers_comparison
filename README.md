# Transformers_comparison
Comparison of state of the art BERT (Devlin &amp; al, 2018) and its variants DistilBert (Sanh &amp; al, 2019) and ALBERT (Lan &amp; al, 2019)  for text classification using the Transformer package from HuggingFace (https://huggingface.co/transformers/).
The models are evaluated on the IMDB dataset and AG News dataset.
This work was originally done on a local machine and only the final notebook will be put on this repo, without any data.
The comparison of the models was done as a project for the class SYS843 at the ETS.
